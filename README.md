# LLM-Powered Document Q&A (RAG)

This is a personal project where I experiment with building an LLM-powered document question answering system using Python and retrieval-augmented generation (RAG).

## ğŸš€ Overview
This tool allows users to upload PDF or text documents and ask questions about the content. It uses semantic search over embeddings to retrieve relevant context, then generates answers using an LLM.

## ğŸ§  Features
- Upload PDF/text documents  
- Create embeddings and perform vector search (FAISS)  
- Use LLMs to generate answers based on retrieved context  
- Basic API/UI for querying documents  
- Experimenting with prompt engineering and evaluation  

## ğŸ› ï¸ Tech Stack
- Python  
- FAISS (vector database)  
- Transformers / LLM APIs  
- REST API (Flask/FastAPI)  

## ğŸ“Œ Why I built this
I wanted to learn how LLMs can be integrated into user-facing applications and how retrieval-augmented generation improves answer quality.

## ğŸ“ Status
Work in progress â€” actively improving response quality and adding features.
